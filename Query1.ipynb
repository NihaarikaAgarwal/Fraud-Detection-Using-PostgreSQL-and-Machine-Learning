{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86c09e39-65ce-4692-bb51-9681bb5a4ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.5.tar.gz (317.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.2/317.2 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.5-py2.py3-none-any.whl size=317747923 sha256=9046619a5811f08f8b7397bdf17efcf357576cfa5e7bcdb06294b28097cfb97c\n",
      "  Stored in directory: /home/itewari1/.cache/pip/wheels/8f/cb/c0/cc57eb1bf0f9dc87cdaf2b0dbac49e58a210ff68d21d6fc709\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.5\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/itewari1/.local/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/itewari1/.local/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/itewari1/.local/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/itewari1/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (11.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install torch torchvision\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5909492e-a192-43bc-ad43-6ed11eae1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FraudDetection\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# df = spark.read.option(\"header\", True).csv(\"idimage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbb8007a-7aee-4876-97cf-8660ae184c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"multiLine\", True) \\\n",
    "    .option(\"quote\", \"\\\"\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\") \\\n",
    "    .csv(\"heavy_test_query1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bd7af4d-495a-470a-b6ea-c664aa6b952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"heavy_test_query1.csv\")\n",
    "print(len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "934c26ec-95f6-46c4-8c9c-ff76e366a537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count in original DataFrame: 6000\n",
      "+--------------------+\n",
      "|           imageData|\n",
      "+--------------------+\n",
      "|/9j/4AAQSkZJRgABA...|\n",
      "|/9j/4AAQSkZJRgABA...|\n",
      "|/9j/4AAQSkZJRgABA...|\n",
      "|/9j/4AAQSkZJRgABA...|\n",
      "|/9j/4AAQSkZJRgABA...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(f\"Row count in original DataFrame: {df.count()}\")\n",
    "df.select(\"imageData\").show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "626d0141-e116-4325-a763-86982f978faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "import time\n",
    "\n",
    "# Step 1: Load base MobileNetV3 Small architecture\n",
    "model = models.mobilenet_v3_small(pretrained=False)\n",
    "\n",
    "# Step 2: Rebuild the classifier to match training setup\n",
    "model.classifier[3] = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(in_features=model.classifier[3].in_features, out_features=2)\n",
    ")\n",
    "\n",
    "# Step 3: Load the trained state_dict\n",
    "state_dict = torch.load(\"mobileNetV3_fraud_model_3.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Step 4: Define the inference transform (no augmentation)\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Step 5: Define the fraud prediction function\n",
    "def infer_fraud(image_base64: str) -> int:\n",
    "    try:\n",
    "        image_bytes = base64.b64decode(image_base64)\n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "        image = inference_transform(image).unsqueeze(0)  # batch size = 1\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            prediction = torch.argmax(output, dim=1).item()\n",
    "        return prediction  # 0 = Genuine, 1 = Fraud\n",
    "    except Exception as e:\n",
    "        print(f\"Inference error: {e}\")\n",
    "        return -1\n",
    "\n",
    "# Step 6: Register UDF in Spark\n",
    "infer_fraud_udf = udf(infer_fraud, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08fb3c70-5605-47da-ba50-68767c847746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/03 21:56:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/03 21:56:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 43:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|  label|count|\n",
      "+-------+-----+\n",
      "|Genuine| 4822|\n",
      "|  Fraud| 1178|\n",
      "+-------+-----+\n",
      "\n",
      "\n",
      "Total images: 6000\n",
      "Total end-to-end processing time: 61.68 seconds\n",
      "Avg latency per image: 0.0103 seconds/image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Step 1: Count number of input records\n",
    "num_images = df.count()\n",
    "\n",
    "# Step 2: Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Assume 'df' has a column 'Base64' with base64-encoded images\n",
    "df_with_preds = df.withColumn(\"prediction\", infer_fraud_udf(df[\"imageData\"]))\n",
    "\n",
    "# Map predictions to labels\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_labeled = df_with_preds.withColumn(\n",
    "    \"label\",\n",
    "    when(df_with_preds[\"prediction\"] == 0, \"Genuine\")\n",
    "    .when(df_with_preds[\"prediction\"] == 1, \"Fraud\")\n",
    "    .otherwise(\"Error\")\n",
    ")\n",
    "\n",
    "# Group by and count labels\n",
    "result = df_labeled.groupBy(\"label\").count()\n",
    "\n",
    "result.show()\n",
    "\n",
    "# Step 4: Stop timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Step 5: Compute metrics\n",
    "total_time = end_time - start_time\n",
    "latency_per_image = total_time / num_images if num_images > 0 else 0\n",
    "\n",
    "# Step 6: Print results\n",
    "print(f\"\\nTotal images: {num_images}\")\n",
    "print(f\"Total end-to-end processing time: {total_time:.2f} seconds\")\n",
    "print(f\"Avg latency per image: {latency_per_image:.4f} seconds/image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbba99-e9d3-44e0-80ac-314bddc5cca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
